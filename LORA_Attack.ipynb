{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import timeit\n",
    "from tqdm import tqdm\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "\n",
    "text_data = load_dataset(\"yahoo_answers_topics\") #load_dataset(\"ag_news\")\n",
    "\n",
    "def prepare_data(data_point):\n",
    "    data_point['text'] = data_point['question_title'] + \" \" + data_point['question_content']\n",
    "    return data_point\n",
    "\n",
    "text_data = text_data.map(prepare_data)\n",
    "text_data = text_data.rename_column(\"topic\", \"label\")\n",
    "\n",
    "sequences = text_data['train']['text']\n",
    "labels=text_data['train']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from transformers import RobertaTokenizer\n",
    "# Initialize tokenizer\n",
    "#seq_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "seq_tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "# Define the Dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        assert len(texts) == len(labels), \"Texts and labels must have the same length.\"\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Tokenize and encode the input text\n",
    "        encoded = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in encoded.items()}\n",
    "        # Add the label to the item\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "\n",
    "# Dataset and DataLoader creation\n",
    "\n",
    "MAX_WORDS=18\n",
    "length=len(sequences[0:5000])\n",
    "trainset = TextDataset(\n",
    "        texts=sequences[0:length],\n",
    "        labels=labels[0:length],\n",
    "        tokenizer=seq_tokenizer,\n",
    "        max_length=MAX_WORDS  # Modify if needed based on your text length\n",
    "    )\n",
    "trainloader = DataLoader(trainset, batch_size=48, shuffle=True)\n",
    "torch.manual_seed(42)\n",
    "    # Test a batch\n",
    "index = iter(trainloader)\n",
    "batch = next(index)\n",
    "#print(batch)  # View the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "\n",
    "\n",
    "input_idx = batch['input_ids']\n",
    "attention_masks = batch['attention_mask']  #\n",
    "labels = batch['labels']  # Labels tensor\n",
    "\n",
    "decoded = seq_tokenizer.batch_decode(input_idx, skip_special_tokens=False)\n",
    "\n",
    "tokenized_sequences = [seq_tokenizer.convert_ids_to_tokens(ids) for ids in input_idx]\n",
    "\n",
    "    # Print the tokenized sentences\n",
    "# for i, tok in enumerate(tokenized_sequences):\n",
    "#     print(f\"Sequence {i + 1} Tokens:\")\n",
    "#     print(tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "EPOCHS =  1 #40\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "global GLOBAL_VAR\n",
    "GLOBAL_VAR=0\n",
    "DROPOUT = 0 # 0.001\n",
    "#HIDDEN_DIM = 768\n",
    "ADAM_WEIGHT_DECAY = 0\n",
    "ADAM_BETAS = (0.9, 0.999)\n",
    "#ACTIVATION=\"gelu\"\n",
    "NUM_ENCODERS = 1\n",
    "\n",
    "NUM_PATCHES = MAX_WORDS\n",
    "\n",
    "EMBED_DIM = 768\n",
    "NUM_HEADS = 12 #NUM_PATCHES+1\n",
    "HEAD_DIM= EMBED_DIM//NUM_HEADS\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = \"cpu\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaModel, BertModel\n",
    "import torch\n",
    "# Load the pretrained RoBERTa model\n",
    "model_pretrained = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Extract the word embeddings from the pretrained model\n",
    "embeddings = model_pretrained.get_input_embeddings().weight.detach().cpu()\n",
    "\n",
    "# print(embeddings.shape)\n",
    "# model_pretrained = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# # Extract the word embeddings from the pretrained model\n",
    "# embeddings = model_pretrained.get_input_embeddings().weight.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Roberta_arch import RoBERTa\n",
    "from roberta_module import RoBERTa\n",
    "r=4#125\n",
    "#model = ViT(r,EMBED_DIM, PATCH_DIM, PATCH_SIZE, NUM_PATCHES,NUM_HEADS, HEAD_DIM, DROPOUT, CHANNELS, NUM_CLASSES).to(device)\n",
    "model = RoBERTa(r, embedding_dim=768, vocab_size=embeddings.shape[0], max_seq_len=MAX_WORDS, num_head=NUM_HEADS, dim_head=HEAD_DIM, dropout=0, num_classes=NUM_CLASSES)\n",
    "# Disable gradients for the embedding layer in the BERT model\n",
    "for param in model.embedding.word_embeddings.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#print(model(input_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "w_glob=model.state_dict()\n",
    "#Use the pretrained word_embedding without any malicious modification\n",
    "w_glob['embedding.word_embeddings.weight']=copy.deepcopy(embeddings)\n",
    "#print(w_glob.keys())\n",
    "D=EMBED_DIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Design the parameters\n",
    "c=10**2\n",
    "c2=3\n",
    "target_encoders=range(1,5)\n",
    "from Design_Model_LORA import Design\n",
    "\n",
    "All_PATCH=NUM_PATCHES+1\n",
    "ENCODER_NO=12\n",
    "\n",
    "\n",
    "malicious_model=Design(r, c, c2, EMBED_DIM,EMBED_DIM,NUM_HEADS, NUM_PATCHES)\n",
    "\n",
    "w_glob['embedding.position_embeddings']=malicious_model.position_encoding(w_glob,HEAD_DIM)\n",
    "\n",
    "\n",
    "std1=torch.std(w_glob['embedding.position_embeddings'][0][2])\n",
    "mu1=torch.mean(w_glob['embedding.position_embeddings'][0][2])\n",
    "\n",
    "w_glob['embedding.LN.weight']=std1*torch.ones(w_glob['embedding.LN.weight'].size())\n",
    "w_glob['embedding.LN.bias']=mu1*torch.ones(w_glob['embedding.LN.bias'].size())\n",
    "patch_id=range(1,r*len(target_encoders)+1)\n",
    "\n",
    "for i in range(1,ENCODER_NO+1):\n",
    "  key01=f'encoder{i}.attn.Bq.weight'\n",
    "  w_glob[key01]=torch.zeros(w_glob[key01].size())\n",
    "\n",
    "  key02=f'encoder{i}.attn.Bk.weight'\n",
    "  w_glob[key02]=torch.zeros(w_glob[key02].size())\n",
    "\n",
    "  key03=f'encoder{i}.attn.Bv.weight'\n",
    "  w_glob[key03]=torch.zeros(w_glob[key03].size())\n",
    "\n",
    "  key04=f'encoder{i}.attn.Aq.weight'\n",
    "  w_glob[key04]=torch.zeros(w_glob[key04].size())\n",
    "\n",
    "  key05=f'encoder{i}.attn.Ak.weight'\n",
    "  w_glob[key05]=torch.zeros(w_glob[key05].size())\n",
    "\n",
    "  key06=f'encoder{i}.attn.Av.weight'\n",
    "  w_glob[key06]=torch.zeros(w_glob[key06].size())\n",
    "\n",
    "for i in range(1,ENCODER_NO): #ENCODER_NO):\n",
    "\n",
    "    w_glob[f'encoder{i}.attn.QKV.weight']=malicious_model.attention(w_glob[f'encoder{i}.attn.QKV.weight'])\n",
    "    w_glob[f'encoder{i}.attn.QKV.bias']=torch.zeros(w_glob[f'encoder{i}.attn.QKV.bias'].size())\n",
    "\n",
    "\n",
    "    key1=f'encoder{i}.mlp.fc1.weight'\n",
    "    w_glob[key1]=torch.zeros(w_glob[key1].size())\n",
    "\n",
    "    key2=f'encoder{i}.mlp.fc2.weight'\n",
    "    w_glob[key2]=torch.zeros(w_glob[key2].size())\n",
    "\n",
    "    key3=f'encoder{i}.mlp.fc1.bias'\n",
    "    w_glob[key3]=torch.zeros(w_glob[key3].size())\n",
    "    #w_glob[key3][0:EMBED_DIM]=high*torch.ones(w_glob[key3][0:EMBED_DIM].size())\n",
    "\n",
    "    key4=f'encoder{i}.mlp.fc2.bias'\n",
    "    #w_glob[key4]=torch.zeros(w_glob[key4].size())\n",
    "    w_glob[key4]=torch.zeros(w_glob[key4].size())\n",
    "\n",
    "    key5=f'encoder{i}.attn.msa.weight'\n",
    "    w_glob[key5]=torch.zeros(w_glob[key5].size())\n",
    "\n",
    "    key6=f'encoder{i}.attn.A.weight'\n",
    "    w_glob[key6]=torch.zeros(w_glob[key6].size())\n",
    "\n",
    "    key7=f'encoder{i}.attn.B.weight'\n",
    "    w_glob[key7]=torch.zeros(w_glob[key7].size())\n",
    "\n",
    "    key8=f'encoder{i}.attn.LN1.weight'\n",
    "    w_glob[key8]=std1*torch.ones(w_glob[key8].size())\n",
    "\n",
    "    key9=f'encoder{i}.attn.LN1.bias'\n",
    "    w_glob[key9]=mu1*torch.ones(w_glob[key9].size())\n",
    "\n",
    "    key10=f'encoder{i}.mlp.LN2.weight'\n",
    "    w_glob[key10]=std1*torch.ones(w_glob[key10].size())\n",
    "\n",
    "    key11=f'encoder{i}.mlp.LN2.bias'\n",
    "    w_glob[key11]=mu1*torch.ones(w_glob[key11].size())\n",
    "\n",
    "\n",
    "count=0\n",
    "for target_encoder in target_encoders:\n",
    "    for i in range(r):\n",
    "\n",
    "        w_glob[f'encoder{target_encoder}.attn.A.weight'][i][2*patch_id[count+i]+1]=1\n",
    "\n",
    "        w_glob[f'encoder{target_encoder}.attn.B.weight']=torch.zeros(w_glob['encoder11.attn.B.weight'].size())\n",
    "\n",
    "    count+=r\n",
    "\n",
    "#Encoder 12\n",
    "w_glob['encoder12.attn.QKV.weight']=torch.zeros(w_glob['encoder11.attn.QKV.weight'].size())\n",
    "w_glob['encoder12.attn.QKV.bias']=torch.zeros(w_glob['encoder11.attn.QKV.bias'].size())\n",
    "w_glob['encoder12.attn.QKV.weight'][2*EMBED_DIM:3*EMBED_DIM]=torch.eye(EMBED_DIM) #Set value matrix to identity\n",
    "w_glob['encoder12.attn.msa.weight']=torch.eye(EMBED_DIM)\n",
    "\n",
    "\n",
    "a=torch.zeros(EMBED_DIM)\n",
    "for i in range(NUM_PATCHES+1):\n",
    "    a[2*i]=c/(NUM_PATCHES+1)\n",
    "    a[2*i+1]=-c/(NUM_PATCHES+1)\n",
    "#print(a)\n",
    "for h in range(1, NUM_HEADS):\n",
    "    for i in range(NUM_PATCHES+1):\n",
    "        if i<31:\n",
    "            a[h*HEAD_DIM+2*i]=c2/(NUM_PATCHES+1)\n",
    "            a[h*HEAD_DIM+2*i+1]=-c2/(NUM_PATCHES+1)\n",
    "        else:\n",
    "            a[h*HEAD_DIM+2*31]=c2/(NUM_PATCHES+1)\n",
    "            a[h*HEAD_DIM+2*31+1]=-c2/(NUM_PATCHES+1)\n",
    "\n",
    "a[0]+=c\n",
    "a[1]+=-c\n",
    "for h in range(1, NUM_HEADS):\n",
    "    a[h*HEAD_DIM+0]+=c2\n",
    "    a[h*HEAD_DIM+1]+=c2\n",
    "\n",
    "std2=torch.std(a)\n",
    "mu2=torch.mean(a)\n",
    "\n",
    "w_glob['encoder12.attn.LN1.weight']=std2*torch.ones(w_glob['encoder11.attn.LN1.weight'].size())\n",
    "w_glob['encoder12.attn.LN1.bias']=mu2*torch.ones(w_glob['encoder11.attn.LN1.weight'].size())\n",
    "\n",
    "w_glob['encoder12.attn.A.weight']=torch.zeros(w_glob['encoder12.attn.A.weight'].size())\n",
    "w_glob['encoder12.attn.B.weight']=torch.zeros(w_glob['encoder12.attn.B.weight'].size())\n",
    "\n",
    "w_glob['encoder12.mlp.LN2.weight']=std2*torch.ones(w_glob['encoder11.attn.LN1.weight'].size())\n",
    "w_glob['encoder12.mlp.LN2.bias']=mu2*torch.ones(w_glob['encoder11.attn.LN1.weight'].size())\n",
    "\n",
    "w_glob['encoder12.mlp.fc1.weight']=torch.zeros(w_glob['encoder12.mlp.fc1.weight'].size())\n",
    "\n",
    "w_glob['encoder12.mlp.fc1.bias']=torch.zeros(w_glob['encoder12.mlp.fc1.bias'].size())\n",
    "\n",
    "w_glob['encoder12.mlp.fc2.weight']=torch.zeros(w_glob['encoder12.mlp.fc2.weight'].size())\n",
    "\n",
    "w_glob['encoder12.mlp.fc2.bias']=torch.zeros(w_glob['encoder12.mlp.fc2.bias'].size())\n",
    "\n",
    "\n",
    "\n",
    "w_glob['mlphead.dense.weight'] = torch.eye(EMBED_DIM)\n",
    "w_glob['mlphead.dense.bias'] = torch.zeros(EMBED_DIM)\n",
    "w_glob['mlphead.head.weight']=torch.zeros(w_glob['mlphead.head.weight'].size())\n",
    "w_CLS=10**2\n",
    "for i in range(len(patch_id)):\n",
    "    w_glob['mlphead.head.weight'][0][2*patch_id[i]]=w_CLS\n",
    "w_glob['mlphead.head.bias']=torch.zeros(w_glob['mlphead.head.bias'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GLOBAL_VAR=0\n",
    "model.load_state_dict(w_glob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18])\n"
     ]
    }
   ],
   "source": [
    "from User_Train import train\n",
    "sample=23\n",
    "#target_encoder=8\n",
    "weight_grad=train(target_encoders,sample, model,input_idx, labels)\n",
    "#print(weight_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder:1 words\n",
      "Recovered embedding 1 corresponds to the word: Which\n",
      "Recovered embedding 2 corresponds to the word: Ġk\n",
      "Recovered embedding 3 corresponds to the word: enn\n",
      "Recovered embedding 4 corresponds to the word: edy\n",
      "encoder:2 words\n",
      "Recovered embedding 1 corresponds to the word: Ġdied\n",
      "Recovered embedding 2 corresponds to the word: Ġin\n",
      "Recovered embedding 3 corresponds to the word: Ġa\n",
      "Recovered embedding 4 corresponds to the word: Ġskiing\n",
      "encoder:3 words\n",
      "Recovered embedding 1 corresponds to the word: Ġacc\n",
      "Recovered embedding 2 corresponds to the word: ed\n",
      "Recovered embedding 3 corresponds to the word: ent\n",
      "Recovered embedding 4 corresponds to the word: ?\n",
      "encoder:4 words\n",
      "Recovered embedding 1 corresponds to the word: Ġ\n",
      "Recovered embedding 2 corresponds to the word: </s>\n",
      "Recovered embedding 3 corresponds to the word: <pad>\n",
      "Recovered embedding 4 corresponds to the word: <pad>\n"
     ]
    }
   ],
   "source": [
    "weight=w_CLS#*w_v\n",
    "LN_scaling= 1 #2*2 #coz divied by 2 two times\n",
    "div_factor=LN_scaling*(NUM_PATCHES+1)\n",
    "a=c**2\n",
    "b=std1**2*D\n",
    "new_scaling=a/b\n",
    "noise_std=0 #0.1\n",
    "from reconstruction import recover1, recover2\n",
    "\n",
    "\n",
    "for u in range(1,len(target_encoders)+1):\n",
    "    print(f'encoder:{u} words')\n",
    "    recovered_embed=recover1(noise_std, patch_id[r*(u-1):r*u], w_glob, weight_grad[u-1].unsqueeze(0),weight, div_factor, new_scaling,D)\n",
    "    recovered_words=recover2(patch_id[r*(u-1):r*u], recovered_embed, w_glob, seq_tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth 1 corresponds to the word: Which\n",
      "ground truth 2 corresponds to the word: Ġk\n",
      "ground truth 3 corresponds to the word: enn\n",
      "ground truth 4 corresponds to the word: edy\n",
      "ground truth 5 corresponds to the word: Ġdied\n",
      "ground truth 6 corresponds to the word: Ġin\n",
      "ground truth 7 corresponds to the word: Ġa\n",
      "ground truth 8 corresponds to the word: Ġskiing\n",
      "ground truth 9 corresponds to the word: Ġacc\n",
      "ground truth 10 corresponds to the word: ed\n",
      "ground truth 11 corresponds to the word: ent\n",
      "ground truth 12 corresponds to the word: ?\n",
      "ground truth 13 corresponds to the word: Ġ\n",
      "ground truth 14 corresponds to the word: </s>\n",
      "ground truth 15 corresponds to the word: <pad>\n",
      "ground truth 16 corresponds to the word: <pad>\n"
     ]
    }
   ],
   "source": [
    "vocab = seq_tokenizer.get_vocab()\n",
    "index_to_token = {index: token for token, index in vocab.items()}\n",
    "for t in range(0,len(patch_id)):\n",
    "    ground_truth=[input_idx[sample][patch_id[t]]]\n",
    "    words = [index_to_token[idx.item()] if isinstance(idx, torch.Tensor) else index_to_token[idx] for idx in ground_truth]\n",
    "# Print the results\n",
    "    for idx, word in enumerate(words):\n",
    "        print(f\"ground truth {t+1} corresponds to the word: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
